{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "ywZ6aJyNoN7L"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2023-11-29 19:51:59.031312: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2023-11-29 19:51:59.031358: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2023-11-29 19:51:59.031371: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2023-11-29 19:51:59.035420: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
          ]
        }
      ],
      "source": [
        "from os import environ, path\n",
        "from absl import logging as absl_logging\n",
        "from IPython.display import clear_output\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import ParameterSampler\n",
        "from tensorflow.keras.callbacks import EarlyStopping\n",
        "import os\n",
        "from pathlib import Path\n",
        "from glob import glob\n",
        "import numpy as np\n",
        "from tensorflow.keras import layers\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "u4it3O-QpmR8"
      },
      "outputs": [],
      "source": [
        "##Variables\n",
        "IMAGE_SIZE = 128\n",
        "BATCH_SIZE = 8\n",
        "NUM_CLASSES = 104\n",
        "LEARNING_RATE=0.002\n",
        "WEIGHT_DECAY=0.0001\n",
        "MOMENTUM=0.9\n",
        "CLIPNORM=10.0\n",
        "EPOCHS=25"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6Fsy1-aEo-ah",
        "outputId": "25bae9f1-f730-44fe-d27f-2702517ec79f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Models folder already exists\n"
          ]
        }
      ],
      "source": [
        "if os.getenv(\"COLAB_RELEASE_TAG\"):\n",
        "    isInColab = True\n",
        "else:\n",
        "    isInColab = False\n",
        "\n",
        "if isInColab:\n",
        "    from google.colab import drive\n",
        "    drive.mount('/content/gdrive')\n",
        "    data_folder_path = Path(os.getcwd() + r\"/gdrive/My Drive/FoodSeg103/Images\")\n",
        "    models_path = Path(os.getcwd() + r\"/gdrive/My Drive/Models\")\n",
        "else:\n",
        "    data_folder_path = Path(os.getcwd()+ r\"/Dataset/FoodSeg103/Images\")\n",
        "    models_path = Path(os.getcwd() + r\"/Models\")\n",
        "try:\n",
        "    os.mkdir(models_path)\n",
        "    print(\"Models folder created for saving models\")\n",
        "except:\n",
        "    print(\"Models folder already exists\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "f18zrsLPp2We"
      },
      "outputs": [],
      "source": [
        "##Data loading\n",
        "def load_images_combined(NUM_TRAIN_IMAGES, NUM_VAL_IMAGES):\n",
        "    train_images_path = Path(data_folder_path, r\"img_dir/train\")\n",
        "    train_ann_path = Path(data_folder_path, r\"ann_dir/train\")\n",
        "    test_images_path = Path(data_folder_path, r\"img_dir/test\")\n",
        "    test_ann_path = Path(data_folder_path, r\"ann_dir/test\")\n",
        "    \n",
        "    train_images_paths = sorted(os.listdir(train_images_path))\n",
        "    train_ann_paths = sorted(os.listdir(train_ann_path))\n",
        "    test_images_paths = sorted(os.listdir(test_images_path))\n",
        "    test_ann_paths = sorted(os.listdir(test_ann_path))\n",
        "\n",
        "    train_images = train_images_paths[:NUM_TRAIN_IMAGES]\n",
        "    train_masks = train_ann_paths[:NUM_TRAIN_IMAGES]\n",
        "    val_images = test_images_paths[:NUM_VAL_IMAGES]\n",
        "    val_masks = test_ann_paths[:NUM_VAL_IMAGES]\n",
        "\n",
        "    train_images = [str(Path(train_images_path, img)) for img in train_images]\n",
        "    train_masks = [str(Path(train_ann_path, img)) for img in train_masks]\n",
        "    val_images = [str(Path(test_images_path, img)) for img in val_images]\n",
        "    val_masks = [str(Path(test_ann_path, img)) for img in val_masks]\n",
        "\n",
        "    image_paths=sorted(train_images + val_images)\n",
        "    mask_paths=sorted(train_masks + val_masks)\n",
        "\n",
        "    return image_paths, mask_paths\n",
        "\n",
        "image_paths, mask_paths = load_images_combined(4983, 2135)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HZP_MO4vFrOY"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import Sequence\n",
        "from keras.utils import to_categorical\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "class CustomDataGenerator(Sequence):\n",
        "    def __init__(self, image_paths, mask_paths, batch_size, validation_split=0.2):\n",
        "        self.image_paths = image_paths\n",
        "        self.mask_paths = mask_paths\n",
        "        self.batch_size = batch_size\n",
        "        self.validation_split = validation_split\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(len(self.image_paths) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        start = index * self.batch_size\n",
        "        end = (index + 1) * self.batch_size\n",
        "        batch_x, batch_y = self.load_data(start, end)\n",
        "\n",
        "        return batch_x, batch_y\n",
        "        \n",
        "\n",
        "    def load_data(self, start, end):\n",
        "        images = []\n",
        "        masks = []\n",
        "        paths = self.image_paths\n",
        "        for i in range(start, min(end, len(self.image_paths))):\n",
        "            img_img = tf.io.read_file(self.image_paths[i])\n",
        "            img = tf.image.decode_png(img_img, channels=3)\n",
        "            img.set_shape([None, None, 3])\n",
        "            img = tf.image.resize(images=img, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
        "            img = tf.keras.applications.resnet50.preprocess_input(img)\n",
        "            images.append(img)\n",
        "\n",
        "            mask_img = tf.io.read_file(self.mask_paths[i])\n",
        "            mask = tf.image.decode_png(mask_img, channels=1)\n",
        "            mask.set_shape([None, None, 1])\n",
        "            mask = tf.image.resize(images=mask, size=[IMAGE_SIZE, IMAGE_SIZE], method='nearest')\n",
        "            one_hot_mask=to_categorical(mask,num_classes=NUM_CLASSES)\n",
        "            masks.append(one_hot_mask)\n",
        "        return np.array(images), np.array(masks)\n",
        "\n",
        "\n",
        "train_image_paths, val_image_paths, train_mask_paths, val_mask_paths = train_test_split(\n",
        "    image_paths, mask_paths, test_size=0.2)\n",
        "\n",
        "train_data_generator = CustomDataGenerator(train_image_paths, train_mask_paths, batch_size=BATCH_SIZE)\n",
        "val_data_generator = CustomDataGenerator(val_image_paths, val_mask_paths,  batch_size=BATCH_SIZE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "S3BRyPJPFrEw"
      },
      "outputs": [],
      "source": [
        "##The model\n",
        "def convolution_block(\n",
        "    block_input,\n",
        "    num_filters=256,\n",
        "    kernel_size=3,\n",
        "    dilation_rate=1,\n",
        "    padding=\"same\",\n",
        "    use_bias=False,\n",
        "):\n",
        "    x = layers.Conv2D(\n",
        "        num_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        dilation_rate=dilation_rate,\n",
        "        padding=\"same\",\n",
        "        use_bias=use_bias,\n",
        "        kernel_initializer=keras.initializers.HeNormal(),\n",
        "    )(block_input)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "\n",
        "def DilatedSpatialPyramidPooling(dspp_input):\n",
        "    dims = dspp_input.shape\n",
        "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
        "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
        "    out_pool = layers.UpSampling2D(\n",
        "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "\n",
        "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
        "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
        "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
        "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
        "    output = convolution_block(x, kernel_size=1)\n",
        "    return output\n",
        "\n",
        "def DeeplabV3Plus(image_size, num_classes):\n",
        "    model_input = keras.Input(shape=(image_size, image_size, 3))\n",
        "    resnet50 = keras.applications.ResNet50(\n",
        "        weights=\"imagenet\", include_top=False, input_tensor=model_input\n",
        "    )\n",
        "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
        "    x = DilatedSpatialPyramidPooling(x)\n",
        "\n",
        "    input_a = layers.UpSampling2D(\n",
        "        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
        "        interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
        "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
        "    x = convolution_block(x)\n",
        "    x = convolution_block(x)\n",
        "    x = layers.UpSampling2D(\n",
        "        size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
        "        interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\", kernel_initializer=keras.initializers.HeNormal(), activation='softmax')(x)\n",
        "\n",
        "\n",
        "    # Adjust the number of output channels to match the number of classes\n",
        "    # x_out = layers.Conv2D(104, (1, 1), activation='softmax')(model_output)\n",
        "\n",
        "    # Use a Reshape layer to match the output shape to (height, width, num_classes)\n",
        "    # x_out = layers.Reshape((image_size, image_size, 104))(x_out)\n",
        "\n",
        "\n",
        "    return keras.Model(inputs=model_input, outputs=model_output)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [],
      "source": [
        "model=DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_6\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input_7 (InputLayer)        [(None, 128, 128, 3)]        0         []                            \n",
            "                                                                                                  \n",
            " conv1_pad (ZeroPadding2D)   (None, 134, 134, 3)          0         ['input_7[0][0]']             \n",
            "                                                                                                  \n",
            " conv1_conv (Conv2D)         (None, 64, 64, 64)           9472      ['conv1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv1_bn (BatchNormalizati  (None, 64, 64, 64)           256       ['conv1_conv[0][0]']          \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv1_relu (Activation)     (None, 64, 64, 64)           0         ['conv1_bn[0][0]']            \n",
            "                                                                                                  \n",
            " pool1_pad (ZeroPadding2D)   (None, 66, 66, 64)           0         ['conv1_relu[0][0]']          \n",
            "                                                                                                  \n",
            " pool1_pool (MaxPooling2D)   (None, 32, 32, 64)           0         ['pool1_pad[0][0]']           \n",
            "                                                                                                  \n",
            " conv2_block1_1_conv (Conv2  (None, 32, 32, 64)           4160      ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_1_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_1_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_2_conv (Conv2  (None, 32, 32, 64)           36928     ['conv2_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_2_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_2_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block1_0_conv (Conv2  (None, 32, 32, 256)          16640     ['pool1_pool[0][0]']          \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_3_conv (Conv2  (None, 32, 32, 256)          16640     ['conv2_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block1_0_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv2_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_3_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv2_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block1_add (Add)      (None, 32, 32, 256)          0         ['conv2_block1_0_bn[0][0]',   \n",
            "                                                                     'conv2_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block1_out (Activati  (None, 32, 32, 256)          0         ['conv2_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block2_1_conv (Conv2  (None, 32, 32, 64)           16448     ['conv2_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_1_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_1_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_2_conv (Conv2  (None, 32, 32, 64)           36928     ['conv2_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_2_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_2_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block2_3_conv (Conv2  (None, 32, 32, 256)          16640     ['conv2_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block2_3_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv2_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block2_add (Add)      (None, 32, 32, 256)          0         ['conv2_block1_out[0][0]',    \n",
            "                                                                     'conv2_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block2_out (Activati  (None, 32, 32, 256)          0         ['conv2_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv2_block3_1_conv (Conv2  (None, 32, 32, 64)           16448     ['conv2_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_1_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_1_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_2_conv (Conv2  (None, 32, 32, 64)           36928     ['conv2_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_2_bn (BatchNo  (None, 32, 32, 64)           256       ['conv2_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_2_relu (Activ  (None, 32, 32, 64)           0         ['conv2_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv2_block3_3_conv (Conv2  (None, 32, 32, 256)          16640     ['conv2_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv2_block3_3_bn (BatchNo  (None, 32, 32, 256)          1024      ['conv2_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv2_block3_add (Add)      (None, 32, 32, 256)          0         ['conv2_block2_out[0][0]',    \n",
            "                                                                     'conv2_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv2_block3_out (Activati  (None, 32, 32, 256)          0         ['conv2_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block1_1_conv (Conv2  (None, 16, 16, 128)          32896     ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_2_conv (Conv2  (None, 16, 16, 128)          147584    ['conv3_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_2_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_2_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block1_0_conv (Conv2  (None, 16, 16, 512)          131584    ['conv2_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_3_conv (Conv2  (None, 16, 16, 512)          66048     ['conv3_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block1_0_bn (BatchNo  (None, 16, 16, 512)          2048      ['conv3_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_3_bn (BatchNo  (None, 16, 16, 512)          2048      ['conv3_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block1_add (Add)      (None, 16, 16, 512)          0         ['conv3_block1_0_bn[0][0]',   \n",
            "                                                                     'conv3_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block1_out (Activati  (None, 16, 16, 512)          0         ['conv3_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block2_1_conv (Conv2  (None, 16, 16, 128)          65664     ['conv3_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_2_conv (Conv2  (None, 16, 16, 128)          147584    ['conv3_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_2_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_2_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block2_3_conv (Conv2  (None, 16, 16, 512)          66048     ['conv3_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block2_3_bn (BatchNo  (None, 16, 16, 512)          2048      ['conv3_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block2_add (Add)      (None, 16, 16, 512)          0         ['conv3_block1_out[0][0]',    \n",
            "                                                                     'conv3_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block2_out (Activati  (None, 16, 16, 512)          0         ['conv3_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block3_1_conv (Conv2  (None, 16, 16, 128)          65664     ['conv3_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_2_conv (Conv2  (None, 16, 16, 128)          147584    ['conv3_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_2_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_2_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block3_3_conv (Conv2  (None, 16, 16, 512)          66048     ['conv3_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block3_3_bn (BatchNo  (None, 16, 16, 512)          2048      ['conv3_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block3_add (Add)      (None, 16, 16, 512)          0         ['conv3_block2_out[0][0]',    \n",
            "                                                                     'conv3_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block3_out (Activati  (None, 16, 16, 512)          0         ['conv3_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv3_block4_1_conv (Conv2  (None, 16, 16, 128)          65664     ['conv3_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_1_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_1_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_2_conv (Conv2  (None, 16, 16, 128)          147584    ['conv3_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_2_bn (BatchNo  (None, 16, 16, 128)          512       ['conv3_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_2_relu (Activ  (None, 16, 16, 128)          0         ['conv3_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv3_block4_3_conv (Conv2  (None, 16, 16, 512)          66048     ['conv3_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv3_block4_3_bn (BatchNo  (None, 16, 16, 512)          2048      ['conv3_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv3_block4_add (Add)      (None, 16, 16, 512)          0         ['conv3_block3_out[0][0]',    \n",
            "                                                                     'conv3_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv3_block4_out (Activati  (None, 16, 16, 512)          0         ['conv3_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block1_1_conv (Conv2  (None, 8, 8, 256)            131328    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block1_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block1_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_2_conv (Conv2  (None, 8, 8, 256)            590080    ['conv4_block1_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block1_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block1_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block1_0_conv (Conv2  (None, 8, 8, 1024)           525312    ['conv3_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block1_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block1_0_bn (BatchNo  (None, 8, 8, 1024)           4096      ['conv4_block1_0_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_3_bn (BatchNo  (None, 8, 8, 1024)           4096      ['conv4_block1_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block1_add (Add)      (None, 8, 8, 1024)           0         ['conv4_block1_0_bn[0][0]',   \n",
            "                                                                     'conv4_block1_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block1_out (Activati  (None, 8, 8, 1024)           0         ['conv4_block1_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block2_1_conv (Conv2  (None, 8, 8, 256)            262400    ['conv4_block1_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block2_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block2_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_2_conv (Conv2  (None, 8, 8, 256)            590080    ['conv4_block2_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block2_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block2_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block2_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block2_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block2_3_bn (BatchNo  (None, 8, 8, 1024)           4096      ['conv4_block2_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block2_add (Add)      (None, 8, 8, 1024)           0         ['conv4_block1_out[0][0]',    \n",
            "                                                                     'conv4_block2_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block2_out (Activati  (None, 8, 8, 1024)           0         ['conv4_block2_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block3_1_conv (Conv2  (None, 8, 8, 256)            262400    ['conv4_block2_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block3_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block3_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_2_conv (Conv2  (None, 8, 8, 256)            590080    ['conv4_block3_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block3_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block3_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block3_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block3_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block3_3_bn (BatchNo  (None, 8, 8, 1024)           4096      ['conv4_block3_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block3_add (Add)      (None, 8, 8, 1024)           0         ['conv4_block2_out[0][0]',    \n",
            "                                                                     'conv4_block3_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block3_out (Activati  (None, 8, 8, 1024)           0         ['conv4_block3_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block4_1_conv (Conv2  (None, 8, 8, 256)            262400    ['conv4_block3_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block4_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block4_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_2_conv (Conv2  (None, 8, 8, 256)            590080    ['conv4_block4_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block4_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block4_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block4_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block4_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block4_3_bn (BatchNo  (None, 8, 8, 1024)           4096      ['conv4_block4_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block4_add (Add)      (None, 8, 8, 1024)           0         ['conv4_block3_out[0][0]',    \n",
            "                                                                     'conv4_block4_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block4_out (Activati  (None, 8, 8, 1024)           0         ['conv4_block4_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block5_1_conv (Conv2  (None, 8, 8, 256)            262400    ['conv4_block4_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block5_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block5_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_2_conv (Conv2  (None, 8, 8, 256)            590080    ['conv4_block5_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block5_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block5_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block5_3_conv (Conv2  (None, 8, 8, 1024)           263168    ['conv4_block5_2_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block5_3_bn (BatchNo  (None, 8, 8, 1024)           4096      ['conv4_block5_3_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block5_add (Add)      (None, 8, 8, 1024)           0         ['conv4_block4_out[0][0]',    \n",
            "                                                                     'conv4_block5_3_bn[0][0]']   \n",
            "                                                                                                  \n",
            " conv4_block5_out (Activati  (None, 8, 8, 1024)           0         ['conv4_block5_add[0][0]']    \n",
            " on)                                                                                              \n",
            "                                                                                                  \n",
            " conv4_block6_1_conv (Conv2  (None, 8, 8, 256)            262400    ['conv4_block5_out[0][0]']    \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_1_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block6_1_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_1_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block6_1_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " conv4_block6_2_conv (Conv2  (None, 8, 8, 256)            590080    ['conv4_block6_1_relu[0][0]'] \n",
            " D)                                                                                               \n",
            "                                                                                                  \n",
            " conv4_block6_2_bn (BatchNo  (None, 8, 8, 256)            1024      ['conv4_block6_2_conv[0][0]'] \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " conv4_block6_2_relu (Activ  (None, 8, 8, 256)            0         ['conv4_block6_2_bn[0][0]']   \n",
            " ation)                                                                                           \n",
            "                                                                                                  \n",
            " average_pooling2d_6 (Avera  (None, 1, 1, 256)            0         ['conv4_block6_2_relu[0][0]'] \n",
            " gePooling2D)                                                                                     \n",
            "                                                                                                  \n",
            " conv2d_65 (Conv2D)          (None, 1, 1, 256)            65792     ['average_pooling2d_6[0][0]'] \n",
            "                                                                                                  \n",
            " batch_normalization_54 (Ba  (None, 1, 1, 256)            1024      ['conv2d_65[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_66 (Conv2D)          (None, 8, 8, 256)            65536     ['conv4_block6_2_relu[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_67 (Conv2D)          (None, 8, 8, 256)            589824    ['conv4_block6_2_relu[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_68 (Conv2D)          (None, 8, 8, 256)            589824    ['conv4_block6_2_relu[0][0]'] \n",
            "                                                                                                  \n",
            " conv2d_69 (Conv2D)          (None, 8, 8, 256)            589824    ['conv4_block6_2_relu[0][0]'] \n",
            "                                                                                                  \n",
            " tf.nn.relu_54 (TFOpLambda)  (None, 1, 1, 256)            0         ['batch_normalization_54[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_55 (Ba  (None, 8, 8, 256)            1024      ['conv2d_66[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_56 (Ba  (None, 8, 8, 256)            1024      ['conv2d_67[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_57 (Ba  (None, 8, 8, 256)            1024      ['conv2d_68[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " batch_normalization_58 (Ba  (None, 8, 8, 256)            1024      ['conv2d_69[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_18 (UpSampli  (None, 8, 8, 256)            0         ['tf.nn.relu_54[0][0]']       \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " tf.nn.relu_55 (TFOpLambda)  (None, 8, 8, 256)            0         ['batch_normalization_55[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " tf.nn.relu_56 (TFOpLambda)  (None, 8, 8, 256)            0         ['batch_normalization_56[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " tf.nn.relu_57 (TFOpLambda)  (None, 8, 8, 256)            0         ['batch_normalization_57[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " tf.nn.relu_58 (TFOpLambda)  (None, 8, 8, 256)            0         ['batch_normalization_58[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " concatenate_12 (Concatenat  (None, 8, 8, 1280)           0         ['up_sampling2d_18[0][0]',    \n",
            " e)                                                                  'tf.nn.relu_55[0][0]',       \n",
            "                                                                     'tf.nn.relu_56[0][0]',       \n",
            "                                                                     'tf.nn.relu_57[0][0]',       \n",
            "                                                                     'tf.nn.relu_58[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_70 (Conv2D)          (None, 8, 8, 256)            327680    ['concatenate_12[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_59 (Ba  (None, 8, 8, 256)            1024      ['conv2d_70[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " conv2d_71 (Conv2D)          (None, 32, 32, 48)           3072      ['conv2_block3_2_relu[0][0]'] \n",
            "                                                                                                  \n",
            " tf.nn.relu_59 (TFOpLambda)  (None, 8, 8, 256)            0         ['batch_normalization_59[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " batch_normalization_60 (Ba  (None, 32, 32, 48)           192       ['conv2d_71[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " up_sampling2d_19 (UpSampli  (None, 32, 32, 256)          0         ['tf.nn.relu_59[0][0]']       \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " tf.nn.relu_60 (TFOpLambda)  (None, 32, 32, 48)           0         ['batch_normalization_60[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " concatenate_13 (Concatenat  (None, 32, 32, 304)          0         ['up_sampling2d_19[0][0]',    \n",
            " e)                                                                  'tf.nn.relu_60[0][0]']       \n",
            "                                                                                                  \n",
            " conv2d_72 (Conv2D)          (None, 32, 32, 256)          700416    ['concatenate_13[0][0]']      \n",
            "                                                                                                  \n",
            " batch_normalization_61 (Ba  (None, 32, 32, 256)          1024      ['conv2d_72[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " tf.nn.relu_61 (TFOpLambda)  (None, 32, 32, 256)          0         ['batch_normalization_61[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " conv2d_73 (Conv2D)          (None, 32, 32, 256)          589824    ['tf.nn.relu_61[0][0]']       \n",
            "                                                                                                  \n",
            " batch_normalization_62 (Ba  (None, 32, 32, 256)          1024      ['conv2d_73[0][0]']           \n",
            " tchNormalization)                                                                                \n",
            "                                                                                                  \n",
            " tf.nn.relu_62 (TFOpLambda)  (None, 32, 32, 256)          0         ['batch_normalization_62[0][0]\n",
            "                                                                    ']                            \n",
            "                                                                                                  \n",
            " up_sampling2d_20 (UpSampli  (None, 128, 128, 256)        0         ['tf.nn.relu_62[0][0]']       \n",
            " ng2D)                                                                                            \n",
            "                                                                                                  \n",
            " conv2d_74 (Conv2D)          (None, 128, 128, 104)        26728     ['up_sampling2d_20[0][0]']    \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 11878824 (45.31 MB)\n",
            "Trainable params: 11846088 (45.19 MB)\n",
            "Non-trainable params: 32736 (127.88 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qAGi5Z2SO8Jw",
        "outputId": "b99c52f7-2911-4e58-e6b2-c6c91210f973"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/999\n",
            "711/711 [==============================] - 161s 206ms/step - loss: 2.2291 - one_hot_mean_io_u_8: 0.0241 - categorical_accuracy: 0.5242 - val_loss: 1.8102 - val_one_hot_mean_io_u_8: 0.0489 - val_categorical_accuracy: 0.5843\n",
            "Epoch 2/999\n",
            "711/711 [==============================] - 146s 206ms/step - loss: 1.6147 - one_hot_mean_io_u_8: 0.0649 - categorical_accuracy: 0.6110 - val_loss: 1.6411 - val_one_hot_mean_io_u_8: 0.0724 - val_categorical_accuracy: 0.6058\n",
            "Epoch 3/999\n",
            "711/711 [==============================] - 164s 230ms/step - loss: 1.3592 - one_hot_mean_io_u_8: 0.1058 - categorical_accuracy: 0.6615 - val_loss: 1.6022 - val_one_hot_mean_io_u_8: 0.0835 - val_categorical_accuracy: 0.6141\n",
            "Epoch 4/999\n",
            "711/711 [==============================] - 164s 231ms/step - loss: 1.1495 - one_hot_mean_io_u_8: 0.1535 - categorical_accuracy: 0.7114 - val_loss: 1.5758 - val_one_hot_mean_io_u_8: 0.0966 - val_categorical_accuracy: 0.6188\n",
            "Epoch 5/999\n",
            "711/711 [==============================] - 154s 217ms/step - loss: 0.9570 - one_hot_mean_io_u_8: 0.2100 - categorical_accuracy: 0.7604 - val_loss: 1.6001 - val_one_hot_mean_io_u_8: 0.1011 - val_categorical_accuracy: 0.6202\n",
            "Epoch 6/999\n",
            "711/711 [==============================] - 160s 225ms/step - loss: 0.7938 - one_hot_mean_io_u_8: 0.2728 - categorical_accuracy: 0.8025 - val_loss: 1.6289 - val_one_hot_mean_io_u_8: 0.1061 - val_categorical_accuracy: 0.6211\n",
            "Epoch 7/999\n",
            "711/711 [==============================] - 150s 210ms/step - loss: 0.6648 - one_hot_mean_io_u_8: 0.3362 - categorical_accuracy: 0.8342 - val_loss: 1.6689 - val_one_hot_mean_io_u_8: 0.1098 - val_categorical_accuracy: 0.6216\n",
            "Epoch 8/999\n",
            "711/711 [==============================] - 155s 218ms/step - loss: 0.5671 - one_hot_mean_io_u_8: 0.3967 - categorical_accuracy: 0.8573 - val_loss: 1.7012 - val_one_hot_mean_io_u_8: 0.1109 - val_categorical_accuracy: 0.6202\n",
            "Epoch 9/999\n",
            "711/711 [==============================] - 151s 212ms/step - loss: 0.4952 - one_hot_mean_io_u_8: 0.4464 - categorical_accuracy: 0.8733 - val_loss: 1.7350 - val_one_hot_mean_io_u_8: 0.1119 - val_categorical_accuracy: 0.6211\n",
            "Epoch 10/999\n",
            "711/711 [==============================] - 148s 208ms/step - loss: 0.4424 - one_hot_mean_io_u_8: 0.4913 - categorical_accuracy: 0.8848 - val_loss: 1.7755 - val_one_hot_mean_io_u_8: 0.1140 - val_categorical_accuracy: 0.6202\n",
            "Epoch 11/999\n",
            "711/711 [==============================] - 148s 207ms/step - loss: 0.4020 - one_hot_mean_io_u_8: 0.5295 - categorical_accuracy: 0.8934 - val_loss: 1.7978 - val_one_hot_mean_io_u_8: 0.1120 - val_categorical_accuracy: 0.6175\n",
            "Epoch 12/999\n",
            "711/711 [==============================] - 148s 208ms/step - loss: 0.3648 - one_hot_mean_io_u_8: 0.5668 - categorical_accuracy: 0.9013 - val_loss: 1.8102 - val_one_hot_mean_io_u_8: 0.1132 - val_categorical_accuracy: 0.6206\n",
            "Epoch 13/999\n",
            "711/711 [==============================] - 151s 212ms/step - loss: 0.3342 - one_hot_mean_io_u_8: 0.5997 - categorical_accuracy: 0.9080 - val_loss: 1.8427 - val_one_hot_mean_io_u_8: 0.1145 - val_categorical_accuracy: 0.6185\n",
            "Epoch 14/999\n",
            "711/711 [==============================] - 148s 208ms/step - loss: 0.3071 - one_hot_mean_io_u_8: 0.6314 - categorical_accuracy: 0.9138 - val_loss: 1.8694 - val_one_hot_mean_io_u_8: 0.1141 - val_categorical_accuracy: 0.6196\n",
            "Epoch 15/999\n",
            "711/711 [==============================] - 149s 210ms/step - loss: 0.2869 - one_hot_mean_io_u_8: 0.6548 - categorical_accuracy: 0.9180 - val_loss: 1.8965 - val_one_hot_mean_io_u_8: 0.1122 - val_categorical_accuracy: 0.6177\n",
            "Epoch 16/999\n",
            "711/711 [==============================] - 148s 209ms/step - loss: 0.2692 - one_hot_mean_io_u_8: 0.6773 - categorical_accuracy: 0.9218 - val_loss: 1.8951 - val_one_hot_mean_io_u_8: 0.1131 - val_categorical_accuracy: 0.6207\n",
            "Epoch 17/999\n",
            "711/711 [==============================] - 150s 211ms/step - loss: 0.2532 - one_hot_mean_io_u_8: 0.7006 - categorical_accuracy: 0.9253 - val_loss: 1.9172 - val_one_hot_mean_io_u_8: 0.1138 - val_categorical_accuracy: 0.6174\n"
          ]
        }
      ],
      "source": [
        "model=DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n",
        "model.compile(\n",
        "    optimizer=keras.optimizers.SGD(learning_rate=0.001, weight_decay=0.0001, momentum=0.9, clipnorm=10.0),\n",
        "      loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "      metrics=[\n",
        "          keras.metrics.OneHotMeanIoU(num_classes=NUM_CLASSES, ignore_class=0),\n",
        "          keras.metrics.CategoricalAccuracy(),\n",
        "      ])\n",
        "\n",
        "early_stopping = EarlyStopping(monitor='val_categorical_accuracy', patience=10, restore_best_weights=True)\n",
        "\n",
        "history = model.fit(\n",
        "    train_data_generator,\n",
        "    steps_per_epoch=len(train_image_paths)//BATCH_SIZE,\n",
        "    validation_data=val_data_generator,\n",
        "    validation_steps=len(val_image_paths)//BATCH_SIZE,\n",
        "    epochs=999,\n",
        "    callbacks=[early_stopping]\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [],
      "source": [
        "from datetime import datetime\n",
        "def saveModel(model, history):\n",
        "    dt_string = datetime.now().strftime(\"%d%m%Y-%H:%M:%S\")\n",
        "    save_name = \"model_\" + dt_string\n",
        "    folder_save_path = os.path.join(models_path, Path(save_name))\n",
        "    os.mkdir(folder_save_path)\n",
        "    his_save_path = os.path.join(folder_save_path, Path(r\"history.npy\"))\n",
        "    model_save_path = os.path.join(folder_save_path, Path(r\"model.keras\"))\n",
        "    np.save(his_save_path,history)\n",
        "    model.save(model_save_path)\n",
        "\n",
        "saveModel(model, history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "bmj8XoYcO8HM"
      },
      "outputs": [],
      "source": [
        "class_labels={0:'background',1:'candy',2:'egg tart',3:'french fries',4:'chocolate',5:'biscuit',6:'popcorn',7:'pudding',8:'ice cream',9:'cheese butter',10:'cake',11:'wine',12:'milkshake',13:'coffee',14:'juice',15:'milk',16:'tea',17:'almond',18:'red beans',19:'cashew',20:'dried cranberries',21:'soy',22:'walnut',23:'peanut',24:'egg',25:'apple',26:'date',27:'apricot',28:'avocado',29:'banana',30:'strawberry',31:'cherry',32:'blueberry',33:'raspberry',34:'mango',35:'olives',36:'peach',37:'lemon',38:'pear',39:'fig',40:'pineapple',41:'grape',42:'kiwi',43:'melon',44:'orange',45:'watermelon',46:'steak',47:'pork',48:'chicken duck',49:'sausage',50:'fried meat',51:'lamb',52:'sauce',53:'crab',54:'fish',55:'shellfish',56:'shrimp',57:'soup',58:'bread',59:'corn',60:'hamburg',61:'pizza',62:' hanamaki baozi',63:'wonton dumplings',64:'pasta',65:'noodles',66:'rice',67:'pie',68:'tofu',69:'eggplant',70:'potato',71:'garlic',72:'cauliflower',73:'tomato',74:'kelp',75:'seaweed',76:'spring onion',77:'rape',78:'ginger',79:'okra',80:'lettuce',81:'pumpkin',82:'cucumber',83:'white radish',84:'carrot',85:'asparagus',86:'bamboo shoots',87:'broccoli',88:'celery stick',89:'cilantro mint',90:'snow peas',91:' cabbage',92:'bean sprouts',93:'onion',94:'pepper',95:'green beans',96:'French beans',97:'king oyster mushroom',98:'shiitake',99:'enoki mushroom',100:'oyster mushroom',101:'white button mushroom',102:'salad',103:'other ingredients'}\n",
        "\n",
        "def predict(model, images, index, useTrainingImages):\n",
        "    ImageIndex = index\n",
        "\n",
        "    if useTrainingImages:\n",
        "      img_path = train_image_paths[ImageIndex]\n",
        "      ann_path = images[\"train_masks\"][ImageIndex]\n",
        "    else:\n",
        "      img_path = images[\"val_images\"][ImageIndex]\n",
        "      ann_path = images[\"val_masks\"][ImageIndex]\n",
        "\n",
        "    processed_image = read_image(img_path)[None,:,:,:]\n",
        "    result = model.predict(processed_image)\n",
        "    result = result.squeeze()\n",
        "    return result\n",
        "\n",
        "\n",
        "def plot_images_withLegends(image_number):\n",
        "\n",
        "  # train_image_paths, val_image_paths, train_mask_paths, val_mask_paths\n",
        "  \n",
        "  image = cv2.resize(cv2.cvtColor(cv2.imread(val_image_paths[image_number]), cv2.COLOR_BGR2RGB), dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n",
        "  mask_img = tf.io.read_file(val_mask_paths[image_number])\n",
        "\n",
        "  prediction = model.predict(image)\n",
        "  # mask = read_image(val_mask_paths[image_number])\n",
        "  mask = tf.image.decode_png(mask_img, channels=1)\n",
        "  mask.set_shape([None, None, 1])\n",
        "  mask = tf.image.resize(images=mask, size=[IMAGE_SIZE, IMAGE_SIZE], method='nearest')\n",
        "  one_hot_mask=to_categorical(mask,num_classes=NUM_CLASSES)\n",
        "  # prediction=  predict(model, images, image_number, True)\n",
        "\n",
        "  colormap = plt.cm.get_cmap('viridis', len(class_labels))  # Use the number of unique classes\n",
        "  # Convert RGB to grayscale if needed\n",
        "  if len(mask.shape) == 3:\n",
        "      mask = np.mean(mask, axis=-1)\n",
        "\n",
        "  # Convert selected channel to grayscale\n",
        "  predicted_classes = prediction.argmax(axis=-1)\n",
        "\n",
        "# Get unique class indices present in the image\n",
        "  unique_classes = np.unique(predicted_classes)\n",
        "\n",
        "  # Convert to RGB using the colormap\n",
        "  rgb_image = colormap(predicted_classes)[:, :, :3]\n",
        "\n",
        "  # Convert RGB to grayscale\n",
        "  gray_image = np.mean(rgb_image, axis=-1)\n",
        "\n",
        "  # Display the result with dynamic legend\n",
        "  fig, axes = plt.subplots(1, 3, figsize=(15, 5))\n",
        "\n",
        "  # Display the normal image with colors\n",
        "  axes[0].imshow(image, cmap='viridis')\n",
        "  axes[0].axis('off')\n",
        "  axes[0].set_title('Normal Image')\n",
        "\n",
        "  # Display the mask image as grayscale\n",
        "  axes[1].imshow(mask, cmap='gray')\n",
        "  axes[1].axis('off')\n",
        "  axes[1].set_title('Mask Image (Grayscale)')\n",
        "\n",
        "  # Display the prediction image for the selected class as grayscale\n",
        "  axes[2].imshow(gray_image, cmap='gray')\n",
        "  axes[2].axis('off')\n",
        "  axes[2].set_title(f'Prediction (Grayscale) for Class')\n",
        "\n",
        "  # Create a dynamic legend for unique classes in the prediction image\n",
        "  colormapLegend = plt.cm.get_cmap('gray', 104)\n",
        "  unique_classes = np.unique(predicted_classes)\n",
        "  # legend_elements = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor='gray', markersize=10, label=class_labels[int(j)]) for j in range(len(unique_classes))]\n",
        "  legend_elements = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=colormapLegend(i)[:3], markersize=10, label=class_labels[i]) for i in unique_classes]\n",
        "  ax_inset = axes[2].inset_axes([1.05, 0, 0.2, 1])\n",
        "  ax_inset.legend(handles=legend_elements, loc='center', bbox_to_anchor=(0, 0.5))\n",
        "  ax_inset.axis('off')\n",
        "\n",
        "\n",
        "  plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "id": "zQ6X3OjBO8EV",
        "outputId": "1a21d7a2-2d47-4c26-a188-e35068f2d1f6"
      },
      "outputs": [
        {
          "ename": "ValueError",
          "evalue": "in user code:\n\n    File \"/home/casper/miniconda3/envs/dl/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2416, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/casper/miniconda3/envs/dl/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2401, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/casper/miniconda3/envs/dl/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2389, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/casper/miniconda3/envs/dl/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2357, in predict_step\n        return self(x, training=False)\n    File \"/home/casper/miniconda3/envs/dl/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/casper/miniconda3/envs/dl/lib/python3.9/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_9\" is incompatible with the layer: expected shape=(None, 128, 128, 3), found shape=(32, 256, 3)\n",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[1;32m/home/casper/projects/dl/DL/newSetupOskar2611_2.ipynb Cell 20\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/casper/projects/dl/DL/newSetupOskar2611_2.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m plot_images_withLegends(\u001b[39m0\u001b[39;49m)\n",
            "\u001b[1;32m/home/casper/projects/dl/DL/newSetupOskar2611_2.ipynb Cell 20\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/casper/projects/dl/DL/newSetupOskar2611_2.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=22'>23</a>\u001b[0m image \u001b[39m=\u001b[39m cv2\u001b[39m.\u001b[39mresize(cv2\u001b[39m.\u001b[39mcvtColor(cv2\u001b[39m.\u001b[39mimread(val_image_paths[image_number]), cv2\u001b[39m.\u001b[39mCOLOR_BGR2RGB), dsize\u001b[39m=\u001b[39m(\u001b[39m256\u001b[39m, \u001b[39m256\u001b[39m), interpolation\u001b[39m=\u001b[39mcv2\u001b[39m.\u001b[39mINTER_CUBIC)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/casper/projects/dl/DL/newSetupOskar2611_2.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=23'>24</a>\u001b[0m mask_img \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mread_file(val_mask_paths[image_number])\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/home/casper/projects/dl/DL/newSetupOskar2611_2.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=25'>26</a>\u001b[0m prediction \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mpredict(image)\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/casper/projects/dl/DL/newSetupOskar2611_2.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=26'>27</a>\u001b[0m \u001b[39m# mask = read_image(val_mask_paths[image_number])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/home/casper/projects/dl/DL/newSetupOskar2611_2.ipynb#X14sdnNjb2RlLXJlbW90ZQ%3D%3D?line=27'>28</a>\u001b[0m mask \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mdecode_png(mask_img, channels\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\n",
            "File \u001b[0;32m~/miniconda3/envs/dl/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
            "File \u001b[0;32m/tmp/__autograph_generated_filetg7oe7r1.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__predict_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
            "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/casper/miniconda3/envs/dl/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2416, in predict_function  *\n        return step_function(self, iterator)\n    File \"/home/casper/miniconda3/envs/dl/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2401, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/casper/miniconda3/envs/dl/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2389, in run_step  **\n        outputs = model.predict_step(data)\n    File \"/home/casper/miniconda3/envs/dl/lib/python3.9/site-packages/keras/src/engine/training.py\", line 2357, in predict_step\n        return self(x, training=False)\n    File \"/home/casper/miniconda3/envs/dl/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py\", line 70, in error_handler\n        raise e.with_traceback(filtered_tb) from None\n    File \"/home/casper/miniconda3/envs/dl/lib/python3.9/site-packages/keras/src/engine/input_spec.py\", line 298, in assert_input_compatibility\n        raise ValueError(\n\n    ValueError: Input 0 of layer \"model_9\" is incompatible with the layer: expected shape=(None, 128, 128, 3), found shape=(32, 256, 3)\n"
          ]
        }
      ],
      "source": [
        "plot_images_withLegends(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3L-s19mO7_5",
        "outputId": "40062960-e0f9-4f81-adab-dac38f1e8a4a"
      },
      "outputs": [],
      "source": [
        " max_pixel_value = 0\n",
        "\n",
        " for image_path in mask_paths:\n",
        "  # Load and preprocess image\n",
        "  # img_img = tf.io.read_file(self.image_paths[i])\n",
        "  # img = tf.image.decode_png(img_img, channels=3)\n",
        "  # img.set_shape([None, None, 3])\n",
        "  # img = tf.image.resize(images=img, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
        "  # img = tf.keras.applications.resnet50.preprocess_input(img)\n",
        "  # batch_x.append(img)\n",
        "\n",
        "  # Load and preprocess mask\n",
        "  mask_img = tf.io.read_file(image_path)\n",
        "  mask = tf.image.decode_png(mask_img, channels=1)\n",
        "  mask.set_shape([None, None, 1])\n",
        "  mask = tf.image.resize(images=mask, size=[IMAGE_SIZE, IMAGE_SIZE], method='nearest')\n",
        "  max_value_in_image = np.max(mask)\n",
        "  max_pixel_value = max(max_pixel_value, max_value_in_image)\n",
        "  # batch_y.append(mask)\n",
        "\n",
        "print(\"Overall Maximum Pixel Value:\", max_pixel_value)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jna9zcc0O75b"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qu6lGqdgFqbj"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "def load_and_preprocess_image(image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    image.set_shape([None, None, 3])\n",
        "    image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
        "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
        "    return image\n",
        "\n",
        "##todo maybe the colors should be checked\n",
        "def load_and_preprocess_mask(mask_path):\n",
        "  image = tf.io.read_file(mask_path)\n",
        "  image = tf.image.decode_png(image, channels=1)\n",
        "  image.set_shape([None, None, 1])\n",
        "  image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE], method='nearest')\n",
        "  return image\n",
        "\n",
        "def load_and_preprocess_data(image_path, mask_path):\n",
        "    # Load and preprocess your images and masks\n",
        "    # You may need to resize, normalize, or apply other preprocessing steps\n",
        "    image = load_and_preprocess_image(image_path)\n",
        "    mask = load_and_preprocess_mask(mask_path)\n",
        "    return image, mask\n",
        "\n",
        "dataset = dataset.map(load_and_preprocess_data)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b7wyFl7Xvq8Y"
      },
      "outputs": [],
      "source": [
        "##the model\n",
        "def convolution_block(\n",
        "    block_input,\n",
        "    num_filters=256,\n",
        "    kernel_size=3,\n",
        "    dilation_rate=1,\n",
        "    padding=\"same\",\n",
        "    use_bias=False,\n",
        "):\n",
        "    x = layers.Conv2D(\n",
        "        num_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        dilation_rate=dilation_rate,\n",
        "        padding=\"same\",\n",
        "        use_bias=use_bias,\n",
        "        kernel_initializer=keras.initializers.HeNormal(),\n",
        "    )(block_input)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "\n",
        "def DilatedSpatialPyramidPooling(dspp_input):\n",
        "    dims = dspp_input.shape\n",
        "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
        "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
        "    out_pool = layers.UpSampling2D(\n",
        "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "\n",
        "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
        "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
        "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
        "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
        "    output = convolution_block(x, kernel_size=1)\n",
        "    return output\n",
        "\n",
        "def DeeplabV3Plus(image_size, num_classes):\n",
        "    model_input = keras.Input(shape=(image_size, image_size, 3))\n",
        "    resnet50 = keras.applications.ResNet50(\n",
        "        weights=\"imagenet\", include_top=False, input_tensor=model_input\n",
        "    )\n",
        "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
        "    x = DilatedSpatialPyramidPooling(x)\n",
        "\n",
        "    input_a = layers.UpSampling2D(\n",
        "        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
        "        interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
        "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
        "    x = convolution_block(x)\n",
        "    x = convolution_block(x)\n",
        "    x = layers.UpSampling2D(\n",
        "        size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
        "        interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\", kernel_initializer=keras.initializers.HeNormal())(x)\n",
        "    return keras.Model(inputs=model_input, outputs=model_output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "13WjhwHgTBZH"
      },
      "outputs": [],
      "source": [
        "train_size = int(0.8 * len(images['image']))\n",
        "train_dataset = dataset.take(train_size)\n",
        "val_dataset = dataset.skip(train_size)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 735
        },
        "id": "eZ0yZo6TR0y5",
        "outputId": "80b6f170-ccd2-4ab8-8edf-424932f644ce"
      },
      "outputs": [],
      "source": [
        "model = DeeplabV3Plus(IMAGE_SIZE, NUM_CLASSES)\n",
        "\n",
        "# Define a custom mIoU metric\n",
        "class MeanIoU(tf.keras.metrics.MeanIoU):\n",
        "    def __init__(self, num_classes):\n",
        "        super(MeanIoU, self).__init__(num_classes=num_classes)\n",
        "\n",
        "mean_iou_metric = MeanIoU(NUM_CLASSES)\n",
        "\n",
        "# Compile the model with the custom metric\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy', mean_iou_metric])\n",
        "\n",
        "model.fit(train_dataset, steps_per_epoch=10, epochs=10,validation_data=val_dataset)\n",
        "model.evaluate(test_generator)\n",
        "\n",
        "# Access the mean IoU value\n",
        "mean_iou_value = mean_iou_metric.result().numpy()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "TtnY1pI1YAd7",
        "outputId": "ef577855-da7e-424b-859d-74a05decbfb3"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import os\n",
        "import numpy as np\n",
        "\n",
        "# Path to your dataset\n",
        "dataset_path = Path(os.getcwd() + r\"/gdrive/My Drive/FoodSeg103/Images/img_dir\")\n",
        "\n",
        "def custom_data_generator(image_folder, mask_folder, batch_size=32, target_size=(256, 256)):\n",
        "    image_datagen = ImageDataGenerator(rescale=1./255)\n",
        "    mask_datagen = ImageDataGenerator()\n",
        "\n",
        "    image_generator = image_datagen.flow_from_directory(\n",
        "        image_folder,\n",
        "        class_mode=None,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        seed=42\n",
        "    )\n",
        "\n",
        "    mask_generator = mask_datagen.flow_from_directory(\n",
        "        mask_folder,\n",
        "        class_mode=None,\n",
        "        target_size=target_size,\n",
        "        batch_size=batch_size,\n",
        "        seed=42,\n",
        "        color_mode='grayscale'\n",
        "    )\n",
        "\n",
        "    while True:\n",
        "        image_batch = image_generator.next()\n",
        "        mask_batch = mask_generator.next()\n",
        "        yield image_batch, mask_batch\n",
        "\n",
        "# Create a custom data generator for both train and test\n",
        "train_generator = custom_data_generator(os.path.join(dataset_path, 'train'), os.path.join(dataset_path, 'masks'))\n",
        "test_generator = custom_data_generator(os.path.join(dataset_path, 'test'), os.path.join(dataset_path, 'masks'))\n",
        "\n",
        "# Extract one batch for debugging\n",
        "sample_batch_train = next(train_generator)\n",
        "sample_images_train, sample_masks_train = sample_batch_train[0], sample_batch_train[1]\n",
        "\n",
        "sample_batch_test = next(test_generator)\n",
        "sample_images_test, sample_masks_test = sample_batch_test[0], sample_batch_test[1]\n",
        "\n",
        "# Now, the shape of sample_images_train/masks_train and sample_images_test/masks_test should be (32, 256, 256, 3) and (32, 256, 256, 1) respectively\n",
        "print(sample_images_train.shape, sample_masks_train.shape)\n",
        "print(sample_images_test.shape, sample_masks_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "rlukq-kETADm",
        "outputId": "f929ba96-2121-4e51-8004-1aa95b6b0045"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Path to your dataset\n",
        "dataset_path = Path(os.getcwd() + r\"/gdrive/My Drive/FoodSeg103/Images/img_dir\")\n",
        "\n",
        "# Create an ImageDataGenerator for images\n",
        "image_datagen = ImageDataGenerator(rescale=1./255)\n",
        "image_generator = image_datagen.flow_from_directory(\n",
        "    dataset_path=,\n",
        "    classes=['train', 'test'],  # Include both 'train' and 'test' folders\n",
        "    class_mode=None,\n",
        "    target_size=(256, 256),  # Adjust the target size based on your model input size\n",
        "    batch_size=32,\n",
        "    seed=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 346
        },
        "id": "5VcfG91Av0z6",
        "outputId": "e8f92687-ee48-4a11-ad53-286149663d77"
      },
      "outputs": [],
      "source": [
        "def train_model_new():\n",
        "  model=DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n",
        "  model.compile(\n",
        "    optimizer=keras.optimizers.SGD(\n",
        "        learning_rate=LEARNING_RATE, weight_decay=WEIGHT_DECAY, momentum=MOMENTUM, clipnorm=CLIPNORM\n",
        "    ),\n",
        "    loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "    metrics=['accuracy', tf.keras.metrics.MeanIoU(num_classes=NUM_CLASSES)\n",
        "    ])\n",
        "  history = model.fit(train_dataset, validation_data=val_dataset, epochs=EPOCHS)\n",
        "  return (model, history)\n",
        "\n",
        "t= train_model_new()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4rlF96w-seBF"
      },
      "outputs": [],
      "source": [
        "images = load_images_combined(10,10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AJBeKApJvLH-"
      },
      "outputs": [],
      "source": [
        "train_size = int(0.8 * len(images['image']))\n",
        "train_dataset = dataset.take(train_size)\n",
        "val_dataset = dataset.skip(train_size)\n",
        "\n",
        "# Batch and shuffle the training dataset\n",
        "train_dataset = train_dataset.shuffle(buffer_size=1000).batch(BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
        "\n",
        "# Batch the validation dataset\n",
        "val_dataset = val_dataset.batch(BATCH_SIZE).prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDrIPt8Isywr"
      },
      "outputs": [],
      "source": [
        "singleMask=load_and_preprocess_mask(images['masks'][0])\n",
        "ar"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "iRlL31hhtizF",
        "outputId": "616fd712-bb06-4b5b-c920-1b3f4b3eddd6"
      },
      "outputs": [],
      "source": [
        "img_raw = tf.io.read_file(images['masks'][0])\n",
        "\n",
        "# Decode the image, specifying the channels (1 for grayscale)\n",
        "img_tensor = tf.io.decode_image(img_raw, channels=1, dtype=tf.uint8)\n",
        "\n",
        "# Convert the image to float32 and normalize it to the range [0, 1]\n",
        "img_tensor = tf.image.convert_image_dtype(img_tensor, tf.float32)\n",
        "img_tensor = img_tensor / 103.0  # Assuming the original range is [0, 103]\n",
        "\n",
        "# Print information about the loaded image\n",
        "print(\"Image Shape:\", img_tensor.shape)\n",
        "print(\"Image Data Type:\", img_tensor.dtype)\n",
        "\n",
        "# Display the image using matplotlib or any other plotting library\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(tf.squeeze(img_tensor), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Wq-HT5g8ph9E"
      },
      "outputs": [],
      "source": [
        "##model\n",
        "def convolution_block(\n",
        "    block_input,\n",
        "    num_filters=256,\n",
        "    kernel_size=3,\n",
        "    dilation_rate=1,\n",
        "    padding=\"same\",\n",
        "    use_bias=False,\n",
        "):\n",
        "    x = layers.Conv2D(\n",
        "        num_filters,\n",
        "        kernel_size=kernel_size,\n",
        "        dilation_rate=dilation_rate,\n",
        "        padding=\"same\",\n",
        "        use_bias=use_bias,\n",
        "        kernel_initializer=keras.initializers.HeNormal(),\n",
        "    )(block_input)\n",
        "    x = layers.BatchNormalization()(x)\n",
        "    return tf.nn.relu(x)\n",
        "\n",
        "\n",
        "def DilatedSpatialPyramidPooling(dspp_input):\n",
        "    dims = dspp_input.shape\n",
        "    x = layers.AveragePooling2D(pool_size=(dims[-3], dims[-2]))(dspp_input)\n",
        "    x = convolution_block(x, kernel_size=1, use_bias=True)\n",
        "    out_pool = layers.UpSampling2D(\n",
        "        size=(dims[-3] // x.shape[1], dims[-2] // x.shape[2]), interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "\n",
        "    out_1 = convolution_block(dspp_input, kernel_size=1, dilation_rate=1)\n",
        "    out_6 = convolution_block(dspp_input, kernel_size=3, dilation_rate=6)\n",
        "    out_12 = convolution_block(dspp_input, kernel_size=3, dilation_rate=12)\n",
        "    out_18 = convolution_block(dspp_input, kernel_size=3, dilation_rate=18)\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)([out_pool, out_1, out_6, out_12, out_18])\n",
        "    output = convolution_block(x, kernel_size=1)\n",
        "    return output\n",
        "\n",
        "def DeeplabV3Plus(image_size, num_classes):\n",
        "    model_input = keras.Input(shape=(image_size, image_size, 3))\n",
        "    resnet50 = keras.applications.ResNet50(\n",
        "        weights=\"imagenet\", include_top=False, input_tensor=model_input\n",
        "    )\n",
        "    x = resnet50.get_layer(\"conv4_block6_2_relu\").output\n",
        "    x = DilatedSpatialPyramidPooling(x)\n",
        "\n",
        "    input_a = layers.UpSampling2D(\n",
        "        size=(image_size // 4 // x.shape[1], image_size // 4 // x.shape[2]),\n",
        "        interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "    input_b = resnet50.get_layer(\"conv2_block3_2_relu\").output\n",
        "    input_b = convolution_block(input_b, num_filters=48, kernel_size=1)\n",
        "\n",
        "    x = layers.Concatenate(axis=-1)([input_a, input_b])\n",
        "    x = convolution_block(x)\n",
        "    x = convolution_block(x)\n",
        "    x = layers.UpSampling2D(\n",
        "        size=(image_size // x.shape[1], image_size // x.shape[2]),\n",
        "        interpolation=\"bilinear\",\n",
        "    )(x)\n",
        "    model_output = layers.Conv2D(num_classes, kernel_size=(1, 1), padding=\"same\", kernel_initializer=keras.initializers.HeNormal())(x)\n",
        "    return keras.Model(inputs=model_input, outputs=model_output)\n",
        "\n",
        "\n",
        "def trainModel(Epochs):\n",
        "    model = DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n",
        "    model.compile(\n",
        "      optimizer=keras.optimizers.SGD(\n",
        "          learning_rate=0.002, weight_decay=0.0001, momentum=0.9, clipnorm=10.0\n",
        "      ),\n",
        "      loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "      metrics=[\n",
        "          keras.metrics.MeanIoU(\n",
        "              num_classes=NUM_CLASSES, sparse_y_true=False, sparse_y_pred=False\n",
        "          ),\n",
        "          keras.metrics.CategoricalAccuracy(),\n",
        "      ],)\n",
        "    history = model.fit(train_dataset, validation_data=val_dataset, epochs=Epochs)\n",
        "    return (model, history)\n",
        "\n",
        "\n",
        "def trainNewModel(Epochs):\n",
        "    #Train new model and history\n",
        "    model = DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n",
        "    loss = keras.losses.SparseCategoricalCrossentropy(from_logits=False, ignore_class=None)\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.002),\n",
        "        loss=loss,\n",
        "        # metrics=[keras.metrics.MeanIoU(\n",
        "        #     num_classes=NUM_CLASSES, sparse_y_true=False, sparse_y_pred=False\n",
        "        # ),\n",
        "        # keras.metrics.CategoricalAccuracy(),],\n",
        "        metrics=[tf.keras.metrics.OneHotMeanIoU(num_classes=NUM_CLASSES,ignore_class=0)],\n",
        "        # metrics=[\"accuracy\"],\n",
        "    )\n",
        "    history = model.fit(train_dataset, validation_data=val_dataset, epochs=Epochs)\n",
        "    return (model, history)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "id": "DMOniNFGpRzY",
        "outputId": "9d42c41b-9348-4983-efc9-ad7829dc9e02"
      },
      "outputs": [],
      "source": [
        "def train_model_mean_iou(Epochs):\n",
        "    model = DeeplabV3Plus(image_size=IMAGE_SIZE, num_classes=NUM_CLASSES)\n",
        "    model.compile(\n",
        "      optimizer=keras.optimizers.SGD(\n",
        "          learning_rate=0.002, weight_decay=0.0001, momentum=0.9, clipnorm=10.0\n",
        "      ),\n",
        "      loss=keras.losses.CategoricalCrossentropy(from_logits=False),\n",
        "      metrics=[\n",
        "          keras.metrics.MeanIoU(\n",
        "              num_classes=NUM_CLASSES, sparse_y_true=False, sparse_y_pred=False\n",
        "          ),\n",
        "          keras.metrics.CategoricalAccuracy(),\n",
        "      ],)\n",
        "    history = model.fit(train_dataset, validation_data=val_dataset, epochs=Epochs)\n",
        "    return (model, history)\n",
        "\n",
        "\n",
        "## load data in new manner\n",
        "#loading array with image paths\n",
        "image_paths, mask_paths = load_images_combined(100, 10)\n",
        "\n",
        "def load_and_preprocess_image(image_path):\n",
        "    image = tf.io.read_file(image_path)\n",
        "    image = tf.image.decode_png(image, channels=3)\n",
        "    image.set_shape([None, None, 3])\n",
        "    image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
        "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
        "    return image\n",
        "\n",
        "def load_and_preprocess_mask(mask_path):\n",
        "\n",
        "\n",
        "def load_and_preprocess_data(image_path, mask_path):\n",
        "    # Load and preprocess your images and masks\n",
        "    # You may need to resize, normalize, or apply other preprocessing steps\n",
        "    image = load_and_preprocess_image(image_path)\n",
        "    mask = load_and_preprocess_mask(mask_path)\n",
        "    return image, mask\n",
        "\n",
        "# def load_and_preprocess_image(image_path):\n",
        "#     # Implement image loading and preprocessing (e.g., resizing)\n",
        "#     # Return the preprocessed image as a NumPy array\n",
        "#     return processed_image\n",
        "\n",
        "def load_and_preprocess_mask(mask_path):\n",
        "    # Implement mask loading and preprocessing (e.g., resizing)\n",
        "    # Return the preprocessed mask as a NumPy array\n",
        "    return processed_mask\n",
        "\n",
        "# Load and preprocess the data\n",
        "data = [load_and_preprocess_data(image_path, mask_path) for image_path, mask_path in zip(image_paths, mask_paths)]\n",
        "images, masks = zip(*data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sHFCaUa9pRSC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BIoav0kQpBvQ",
        "outputId": "fdb4c42e-2056-4482-db70-f081a8347fd7"
      },
      "outputs": [],
      "source": [
        "##loading model\n",
        "def loadModel(ModelPath):\n",
        "    print(\"Input the folder of the model to load (the folder should be in the models folder and include a history.npy file and a model.keras file):\")\n",
        "    # load_name = input()\n",
        "    folder_load_path = os.path.join(models_path, Path(ModelPath))\n",
        "    his_load_path = os.path.join(folder_load_path, Path(r\"history.npy\"))\n",
        "    model_load_path = os.path.join(folder_load_path, Path(r\"model.keras\"))\n",
        "    history=np.load(his_load_path,allow_pickle='TRUE').item()\n",
        "    model = keras.models.load_model(model_load_path)\n",
        "    return (model, history)\n",
        "\n",
        "model, history = loadModel(\"Base\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kfxk88tYpCDw"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
