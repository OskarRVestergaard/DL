{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 00:36:20.011212: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-01 00:36:20.011292: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-01 00:36:20.011312: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-01 00:36:20.016327: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-01 00:36:22.169348: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-01 00:36:22.195676: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-01 00:36:22.195718: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-01 00:36:22.198184: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-01 00:36:22.198225: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-01 00:36:22.198244: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-01 00:36:22.300528: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-01 00:36:22.300619: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-01 00:36:22.300631: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1977] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-12-01 00:36:22.300676: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:880] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-12-01 00:36:22.300706: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1886] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 5595 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070 Laptop GPU, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    }
   ],
   "source": [
    "import model_functions as mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, history = mf.load_model(\"model_29112023-21:37:57\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'CustomDataGenerator' object has no attribute 'use_augmentation'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m/home/daniel/DL/Daniel.ipynb Cell 3\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell://wsl%2Bubuntu-22.04/home/daniel/DL/Daniel.ipynb#X22sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m model, history \u001b[39m=\u001b[39m mf\u001b[39m.\u001b[39;49mtrain_new_model(\u001b[39m20\u001b[39;49m)\n",
      "File \u001b[0;32m~/DL/model_functions.py:90\u001b[0m, in \u001b[0;36mtrain_new_model\u001b[0;34m(epochs, useEarlyStopping, loss, optimizer2, data_augmentation_config)\u001b[0m\n\u001b[1;32m     80\u001b[0m model\u001b[39m.\u001b[39mcompile(\n\u001b[1;32m     81\u001b[0m optimizer\u001b[39m=\u001b[39moptimizer2,\n\u001b[1;32m     82\u001b[0m   loss\u001b[39m=\u001b[39mloss,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     85\u001b[0m       keras\u001b[39m.\u001b[39mmetrics\u001b[39m.\u001b[39mCategoricalAccuracy(),\n\u001b[1;32m     86\u001b[0m   ])\n\u001b[1;32m     88\u001b[0m early_stopping \u001b[39m=\u001b[39m EarlyStopping(monitor\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mval_loss\u001b[39m\u001b[39m'\u001b[39m, patience\u001b[39m=\u001b[39m\u001b[39m15\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> 90\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(\n\u001b[1;32m     91\u001b[0m     train_data_generator,\n\u001b[1;32m     92\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49mnum_train_images\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49mbatch_size,\n\u001b[1;32m     93\u001b[0m     validation_data\u001b[39m=\u001b[39;49mval_data_generator,\n\u001b[1;32m     94\u001b[0m     validation_steps\u001b[39m=\u001b[39;49mnum_val_images\u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49mbatch_size,\n\u001b[1;32m     95\u001b[0m     epochs\u001b[39m=\u001b[39;49mepochs,\n\u001b[1;32m     96\u001b[0m     callbacks\u001b[39m=\u001b[39;49m([early_stopping] \u001b[39mif\u001b[39;49;00m useEarlyStopping \u001b[39melse\u001b[39;49;00m [])\n\u001b[1;32m     97\u001b[0m )\n\u001b[1;32m     98\u001b[0m \u001b[39mreturn\u001b[39;00m model, history\n",
      "File \u001b[0;32m~/miniconda3/envs/dl39/lib/python3.9/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/DL/background_model_functions.py:104\u001b[0m, in \u001b[0;36mCustomDataGenerator.__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    102\u001b[0m start \u001b[39m=\u001b[39m index \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size\n\u001b[1;32m    103\u001b[0m end \u001b[39m=\u001b[39m (index \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m) \u001b[39m*\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_size\n\u001b[0;32m--> 104\u001b[0m batch_x, batch_y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mload_data(start, end)\n\u001b[1;32m    106\u001b[0m \u001b[39mreturn\u001b[39;00m batch_x, batch_y\n",
      "File \u001b[0;32m~/DL/background_model_functions.py:115\u001b[0m, in \u001b[0;36mCustomDataGenerator.load_data\u001b[0;34m(self, start, end)\u001b[0m\n\u001b[1;32m    113\u001b[0m raw_img \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mread_file(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimage_paths[i])\n\u001b[1;32m    114\u001b[0m img \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mdecode_png(raw_img, channels\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m)\n\u001b[0;32m--> 115\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49muse_augmentation:\n\u001b[1;32m    116\u001b[0m     img \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mimg_augment(img)\n\u001b[1;32m    117\u001b[0m img\u001b[39m.\u001b[39mset_shape([\u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m, \u001b[39m3\u001b[39m])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'CustomDataGenerator' object has no attribute 'use_augmentation'"
     ]
    }
   ],
   "source": [
    "model, history = mf.train_new_model(20, data_augmentation_config=mf.create_data_augmentation_config())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
