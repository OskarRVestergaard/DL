{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import environ, path\n",
    "from absl import logging as absl_logging\n",
    "from IPython.display import clear_output\n",
    "from tensorflow import keras\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import ParameterSampler\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import os\n",
    "from pathlib import Path\n",
    "from glob import glob\n",
    "import numpy as np\n",
    "from tensorflow.keras import layers\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_image(index):\n",
    "    image = tf.io.read_file(image_paths[index])\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image.set_shape([None, None, 3])\n",
    "    image = tf.image.resize(images=image, size=[IMAGE_SIZE, IMAGE_SIZE])\n",
    "    image = tf.keras.applications.resnet50.preprocess_input(image)\n",
    "    processed_image = image[None, :, :, :]\n",
    "    return processed_image\n",
    "\n",
    "\n",
    "def read_mask(index):\n",
    "    mask = tf.io.read_file(mask_paths[index])\n",
    "    mask = tf.image.decode_png(mask, channels=1)\n",
    "    mask.set_shape([None, None, 1])\n",
    "    mask = tf.image.resize(images=mask, size=[IMAGE_SIZE, IMAGE_SIZE], method=tf.image.ResizeMethod.NEAREST_NEIGHBOR, antialias=False)\n",
    "\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def predict(model, index):\n",
    "    processed_image = read_image(index)\n",
    "    prediction = model.predict(processed_image)\n",
    "    prediction = prediction.squeeze()\n",
    "    return prediction\n",
    "\n",
    "\n",
    "def read_image_raw(index):\n",
    "    image = cv2.resize(cv2.cvtColor(cv2.imread(image_paths[index]),\n",
    "                                    cv2.COLOR_BGR2RGB),\n",
    "                       dsize=(IMAGE_SIZE, IMAGE_SIZE),\n",
    "                       interpolation=cv2.INTER_NEAREST)\n",
    "    return image\n",
    "class_labels = {0: 'background', 1: 'candy', 2: 'egg tart', 3: 'french fries', 4: 'chocolate', 5: 'biscuit',\n",
    "                6: 'popcorn', 7: 'pudding', 8: 'ice cream', 9: 'cheese butter', 10: 'cake', 11: 'wine', 12: 'milkshake',\n",
    "                13: 'coffee', 14: 'juice', 15: 'milk', 16: 'tea', 17: 'almond', 18: 'red beans', 19: 'cashew',\n",
    "                20: 'dried cranberries', 21: 'soy', 22: 'walnut', 23: 'peanut', 24: 'egg', 25: 'apple', 26: 'date',\n",
    "                27: 'apricot', 28: 'avocado', 29: 'banana', 30: 'strawberry', 31: 'cherry', 32: 'blueberry',\n",
    "                33: 'raspberry', 34: 'mango', 35: 'olives', 36: 'peach', 37: 'lemon', 38: 'pear', 39: 'fig',\n",
    "                40: 'pineapple', 41: 'grape', 42: 'kiwi', 43: 'melon', 44: 'orange', 45: 'watermelon', 46: 'steak',\n",
    "                47: 'pork', 48: 'chicken duck', 49: 'sausage', 50: 'fried meat', 51: 'lamb', 52: 'sauce', 53: 'crab',\n",
    "                54: 'fish', 55: 'shellfish', 56: 'shrimp', 57: 'soup', 58: 'bread', 59: 'corn', 60: 'hamburg',\n",
    "                61: 'pizza', 62: ' hanamaki baozi', 63: 'wonton dumplings', 64: 'pasta', 65: 'noodles', 66: 'rice',\n",
    "                67: 'pie', 68: 'tofu', 69: 'eggplant', 70: 'potato', 71: 'garlic', 72: 'cauliflower', 73: 'tomato',\n",
    "                74: 'kelp', 75: 'seaweed', 76: 'spring onion', 77: 'rape', 78: 'ginger', 79: 'okra', 80: 'lettuce',\n",
    "                81: 'pumpkin', 82: 'cucumber', 83: 'white radish', 84: 'carrot', 85: 'asparagus', 86: 'bamboo shoots',\n",
    "                87: 'broccoli', 88: 'celery stick', 89: 'cilantro mint', 90: 'snow peas', 91: ' cabbage',\n",
    "                92: 'bean sprouts', 93: 'onion', 94: 'pepper', 95: 'green beans', 96: 'French beans',\n",
    "                97: 'king oyster mushroom', 98: 'shiitake', 99: 'enoki mushroom', 100: 'oyster mushroom',\n",
    "                101: 'white button mushroom', 102: 'salad', 103: 'other ingredients'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_images_withLegends_focal_nofocal(image_number, model_focal):\n",
    "    colormap = plt.cm.get_cmap('viridis', len(class_labels))\n",
    "    ##raw image\n",
    "    image_raw = read_image_raw(image_number)\n",
    "\n",
    "    # mask image\n",
    "    mask = read_mask(image_number)\n",
    "\n",
    "    image_prediction_focal = predict(model_focal, image_number)\n",
    "    image_prediction_focal = image_prediction_focal.argmax(axis=-1)\n",
    "    rgb_image_focal = colormap(image_prediction_focal)[:, :, :3]\n",
    "\n",
    "\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(15, 3))\n",
    "\n",
    "    axes[0].imshow(image_raw, cmap='viridis')\n",
    "    axes[0].axis('off')\n",
    "    axes[0].set_title('Raw Image')\n",
    "\n",
    "    axes[1].imshow(mask, cmap=colormap, vmin=0, vmax=len(class_labels))\n",
    "    axes[1].axis('off')\n",
    "    axes[1].set_title('Mask Image')\n",
    "\n",
    "\n",
    "    axes[2].imshow(rgb_image_focal, cmap=colormap, vmin=0, vmax=len(class_labels))\n",
    "    axes[2].axis('off')\n",
    "    axes[2].set_title('Best model')\n",
    "\n",
    "    #legends for mask\n",
    "    unique_classes_mask = np.unique(mask)\n",
    "    legend_elements = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=colormap(i)[:3], markersize=10,\n",
    "                                  label=class_labels[i]) for i in unique_classes_mask]\n",
    "    ax_inset1 = axes[1].inset_axes([1.3, 0, 0.2, 1])\n",
    "    ax_inset1.legend(handles=legend_elements, loc='center', bbox_to_anchor=(0, 0.5))\n",
    "    ax_inset1.axis('off')\n",
    "\n",
    "\n",
    "    # legends for prediction\n",
    "    unique_classes_prediction1 = np.unique(image_prediction_focal)\n",
    "    legend_elements1 = [plt.Line2D([0], [0], marker='o', color='w', markerfacecolor=colormap(i)[:3], markersize=10,\n",
    "                                  label=class_labels[i]) for i in unique_classes_prediction1]\n",
    "    ax_inset = axes[2].inset_axes([1.3, 0, 0.2, 1])\n",
    "    ax_inset.legend(handles=legend_elements1, loc='center', bbox_to_anchor=(0, 0.5))\n",
    "    ax_inset.axis('off')\n",
    "\n",
    "\n",
    "    plt.subplots_adjust(wspace=0)\n",
    "    plt.imshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models_path = Path(os.getcwd() + r\"/Models\")\n",
    "data_folder_path = Path(os.getcwd()+ r\"/Dataset/FoodSeg103/Images\")\n",
    "IMAGE_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_combined(NUM_TRAIN_IMAGES, NUM_VAL_IMAGES):\n",
    "    train_images_path = Path(data_folder_path, r\"img_dir/train\")\n",
    "    train_ann_path = Path(data_folder_path, r\"ann_dir/train\")\n",
    "    test_images_path = Path(data_folder_path, r\"img_dir/test\")\n",
    "    test_ann_path = Path(data_folder_path, r\"ann_dir/test\")\n",
    "    \n",
    "    train_images_paths = sorted(os.listdir(train_images_path))\n",
    "    train_ann_paths = sorted(os.listdir(train_ann_path))\n",
    "    test_images_paths = sorted(os.listdir(test_images_path))\n",
    "    test_ann_paths = sorted(os.listdir(test_ann_path))\n",
    "\n",
    "    train_images = train_images_paths[:NUM_TRAIN_IMAGES]\n",
    "    train_masks = train_ann_paths[:NUM_TRAIN_IMAGES]\n",
    "    val_images = test_images_paths[:NUM_VAL_IMAGES]\n",
    "    val_masks = test_ann_paths[:NUM_VAL_IMAGES]\n",
    "\n",
    "    train_images = [str(Path(train_images_path, img)) for img in train_images]\n",
    "    train_masks = [str(Path(train_ann_path, img)) for img in train_masks]\n",
    "    val_images = [str(Path(test_images_path, img)) for img in val_images]\n",
    "    val_masks = [str(Path(test_ann_path, img)) for img in val_masks]\n",
    "\n",
    "    image_paths=sorted(train_images + val_images)\n",
    "    mask_paths=sorted(train_masks + val_masks)\n",
    "\n",
    "    return image_paths, mask_paths\n",
    "\n",
    "image_paths, mask_paths = load_images_combined(4983, 2135)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##loading model\n",
    "def loadModel(ModelPath):\n",
    "    folder_load_path = os.path.join(models_path, Path(ModelPath))\n",
    "    focal = os.path.join(folder_load_path, Path(r\"focal.keras\"))\n",
    "    focal_model = keras.models.load_model(focal)\n",
    "    return focal_model\n",
    "\n",
    "focal = loadModel(\"models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_images_withLegends_focal_nofocal(5, focal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
